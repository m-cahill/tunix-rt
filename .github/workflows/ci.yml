name: CI

on:
  pull_request:
  push:
    branches: [main]

permissions:
  contents: read

jobs:
  # Path filter job - always runs
  # NOTE: paths-filter requires concrete commit SHAs, not symbolic refs like HEAD.
  # - base/ref are resolved from event payloads to ensure deterministic behavior
  # - For PRs: use pull_request.base.sha and pull_request.head.sha
  # - For pushes: use github.event.before and github.sha
  # - fetch-depth: 0 ensures full history is available for diff computation
  # This prevents CI nondeterminism when HEAD doesn't exist or points incorrectly.
  changes:
    runs-on: ubuntu-latest
    outputs:
      backend: ${{ steps.filter.outputs.backend }}
      frontend: ${{ steps.filter.outputs.frontend }}
      e2e: ${{ steps.filter.outputs.e2e }}
      workflow: ${{ steps.filter.outputs.workflow }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      # Sanity check: Ensure base and ref SHAs are resolved correctly
      - name: Validate paths-filter inputs
        run: |
          BASE="${{ github.event_name == 'pull_request' && github.event.pull_request.base.sha || github.event.before }}"
          REF="${{ github.event_name == 'pull_request' && github.event.pull_request.head.sha || github.sha }}"
          echo "Base SHA: $BASE"
          echo "Ref SHA: $REF"
          if [ -z "$BASE" ] || [ -z "$REF" ]; then
            echo "::error::paths-filter base or ref SHA is empty — workflow misconfigured"
            exit 1
          fi
      
      - uses: dorny/paths-filter@v2
        id: filter
        with:
          token: ''
          base: ${{ github.event_name == 'pull_request' && github.event.pull_request.base.sha || github.event.before }}
          ref: ${{ github.event_name == 'pull_request' && github.event.pull_request.head.sha || github.sha }}
          filters: |
            backend:
              - 'backend/**'
            frontend:
              - 'frontend/**'
            e2e:
              - 'e2e/**'
            workflow:
              - '.github/workflows/**'

  # Backend job - runs if backend or workflow changed
  backend:
    runs-on: ubuntu-latest
    needs: changes
    if: needs.changes.outputs.backend == 'true' || needs.changes.outputs.workflow == 'true'
    strategy:
      matrix:
        python-version: ['3.11', '3.12']
    defaults:
      run:
        working-directory: backend
    steps:
      - uses: actions/checkout@v4
      
      - uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'
          cache-dependency-path: 'backend/pyproject.toml'
      
      - name: Install dependencies
        run: python -m pip install -e ".[dev]"
      
      - name: Ruff check
        run: ruff check .
      
      - name: Ruff format check
        run: ruff format --check .
      
      - name: mypy type check
        run: mypy tunix_rt_backend
      
      - name: pytest with coverage
        run: pytest -q --cov=tunix_rt_backend --cov-branch --cov-report=term --cov-report=xml --cov-report=json:coverage.json
      
      - name: Enforce coverage gates (line ≥80%, branch ≥68%)
        run: python tools/coverage_gate.py
      
      - name: Upload coverage
        uses: actions/upload-artifact@v4
        with:
          name: backend-coverage-py${{ matrix.python-version }}
          path: backend/coverage.xml
      
      - name: Migration smoke test
        run: |
          export DATABASE_URL="sqlite+aiosqlite:///./test_migrations.db"
          alembic upgrade head
        env:
          DATABASE_URL: "sqlite+aiosqlite:///./test_migrations.db"

  # Frontend job - runs if frontend or workflow changed
  frontend:
    runs-on: ubuntu-latest
    needs: changes
    if: needs.changes.outputs.frontend == 'true' || needs.changes.outputs.workflow == 'true'
    defaults:
      run:
        working-directory: frontend
    steps:
      - uses: actions/checkout@v4
      
      - uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'
          cache-dependency-path: 'frontend/package-lock.json'
      
      - name: Install dependencies
        run: npm ci
      
      - name: Run tests with coverage
        run: npm run test -- --coverage
      
      - name: Upload coverage
        uses: actions/upload-artifact@v4
        with:
          name: frontend-coverage
          path: frontend/coverage/
          retention-days: 30
      
      - name: Build
        run: npm run build

  # Security: pip-audit (warn-only)
  security-backend:
    runs-on: ubuntu-latest
    needs: changes
    if: needs.changes.outputs.backend == 'true' || needs.changes.outputs.workflow == 'true'
    defaults:
      run:
        working-directory: backend
    steps:
      - uses: actions/checkout@v4
      
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: 'backend/pyproject.toml'
      
      - name: Install dependencies
        run: python -m pip install -e ".[dev]"
      
      - name: Cache security tools
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: security-tools-${{ runner.os }}-${{ hashFiles('backend/pyproject.toml') }}
          restore-keys: |
            security-tools-${{ runner.os }}-
      
      - name: Run pip-audit
        run: |
          pip install pip-audit
          pip-audit --desc --format json --output pip-audit-report.json || true
          pip-audit --desc || true
        continue-on-error: true
      
      - name: Upload pip-audit report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: pip-audit-report
          path: backend/pip-audit-report.json
          retention-days: 30
      
      # M4: SBOM generation temporarily disabled - non-blocking, will fix in M5
      # The cyclonedx-bom tool has PATH/module invocation issues that need investigation
      # This doesn't block M4 E2E verification
      # - name: Install SBOM tool
      #   run: pip install cyclonedx-bom
      # 
      # - name: Generate SBOM
      #   run: python -m cyclonedx_bom requirements backend --format json --output sbom.json
      # 
      # - name: Upload SBOM
      #   uses: actions/upload-artifact@v4
      #   with:
      #     name: backend-sbom
      #     path: backend/sbom.json
      #     retention-days: 90

  # Security: npm audit (warn-only)
  security-frontend:
    runs-on: ubuntu-latest
    needs: changes
    if: needs.changes.outputs.frontend == 'true' || needs.changes.outputs.workflow == 'true'
    defaults:
      run:
        working-directory: frontend
    steps:
      - uses: actions/checkout@v4
      
      - uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'
          cache-dependency-path: 'frontend/package-lock.json'
      
      - name: Install dependencies
        run: npm ci
      
      - name: Run npm audit
        run: |
          npm audit --json > npm-audit-report.json || true
          npm audit || true
        continue-on-error: true
      
      - name: Upload npm audit report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: npm-audit-report
          path: frontend/npm-audit-report.json
          retention-days: 30

  # Security: Secret scanning (runs on push to main only to avoid PR API calls)
  security-secrets:
    runs-on: ubuntu-latest
    if: github.event_name == 'push'
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Run Gitleaks
        uses: gitleaks/gitleaks-action@v2
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  # E2E job - runs if backend, frontend, e2e, or workflow changed
  # M4: Added postgres service, migrations, and smoke checks for deterministic E2E
  e2e:
    runs-on: ubuntu-latest
    needs: changes
    if: |
      needs.changes.outputs.backend == 'true' || 
      needs.changes.outputs.frontend == 'true' || 
      needs.changes.outputs.e2e == 'true' || 
      needs.changes.outputs.workflow == 'true'
    
    # M4: Add Postgres service container with healthcheck
    services:
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: postgres
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    defaults:
      run:
        working-directory: e2e
    
    env:
      REDIAI_MODE: mock
      # M4: Explicit DATABASE_URL for clarity (matches service container)
      DATABASE_URL: postgresql+asyncpg://postgres:postgres@localhost:5432/postgres
    
    steps:
      - uses: actions/checkout@v4
      
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: 'backend/pyproject.toml'
      
      - name: Install backend dependencies
        run: cd ../backend && python -m pip install -e ".[dev]"
      
      # M4: Run migrations before starting servers
      - name: Run database migrations
        run: cd ../backend && alembic upgrade head
        env:
          DATABASE_URL: postgresql+asyncpg://postgres:postgres@localhost:5432/postgres
      
      - uses: actions/setup-node@v4
        with:
          node-version: '18'
      
      - name: Install frontend dependencies
        run: cd ../frontend && npm ci
      
      - name: Install E2E dependencies
        run: npm ci
      
      - name: Install Playwright browsers
        run: npx playwright install chromium --with-deps
      
      # M4: Playwright webServer will start backend + frontend and wait for health URLs
      # No explicit smoke check needed - webServer.url provides built-in waiting
      - name: Run Playwright tests
        run: npx playwright test
      
      - uses: actions/upload-artifact@v4
        if: always()
        with:
          name: playwright-report
          path: e2e/playwright-report/
          retention-days: 7

